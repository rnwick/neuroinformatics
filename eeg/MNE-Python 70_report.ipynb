{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenGL core profile version string: 3.3 (Core Profile) Mesa 20.1.4\n",
      "Platform:      Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-centos-8.3.2011\n",
      "Python:        3.7.10 (default, Feb 26 2021, 18:47:35)  [GCC 7.3.0]\n",
      "Executable:    /home/rnwick/miniconda3/envs/mne-python/bin/python\n",
      "CPU:           x86_64: 12 cores\n",
      "Memory:        7.6 GB\n",
      "\n",
      "mne:           0.22.0\n",
      "numpy:         1.20.3 {blas=NO_ATLAS_INFO, lapack=lapack}\n",
      "scipy:         1.5.3\n",
      "matplotlib:    3.4.2 {backend=module://ipykernel.pylab.backend_inline}\n",
      "\n",
      "sklearn:       0.24.2\n",
      "numba:         0.53.1\n",
      "nibabel:       3.2.1\n",
      "nilearn:       0.7.1\n",
      "dipy:          1.4.1\n",
      "cupy:          Not found\n",
      "pandas:        1.2.4\n",
      "mayavi:        4.7.2\n",
      "pyvista:       0.30.1 {pyvistaqt=0.4.0, OpenGL 3.3 (Core Profile) Mesa 20.1.4 via llvmpipe (LLVM 10.0.0, 128 bits)}\n",
      "vtk:           9.0.1\n",
      "PyQt5:         5.12.3\n"
     ]
    }
   ],
   "source": [
    "#If running this from remote \n",
    "import pyvista as pv\n",
    "pv.start_xvfb()\n",
    "\n",
    "!export MNE_3D_OPTION_ANTIALIAS=false\n",
    "!export MESA_GL_VERSION_OVERRIDE=3.3\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "!glxinfo | grep \"OpenGL core profile version\"\n",
    "!mne sys_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Getting started with ``mne.Report``\n",
    "\n",
    "`mne.Report` is a way to create interactive HTML summaries of your data. These\n",
    "reports can show many different visualizations of one subject's data. A common\n",
    "use case is creating diagnostic summaries to check data quality at different\n",
    "stages in the processing pipeline. The report can show things like plots of\n",
    "data before and after each preprocessing step, epoch rejection statistics, MRI\n",
    "slices with overlaid BEM shells, all the way up to plots of estimated cortical\n",
    "activity.\n",
    "\n",
    "Compared to a Jupyter notebook, `mne.Report` is easier to deploy (the HTML\n",
    "pages it generates are self-contained and do not require a running Python\n",
    "environment) but less flexible (you can't change code and re-run something\n",
    "directly within the browser). This tutorial covers the basics of building a\n",
    "`~mne.Report`. As usual we'll start by importing the modules we need:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting started with :class:`mne.Report`, make sure the files you want\n",
    "to render follow the filename conventions defined by MNE:\n",
    "\n",
    ".. cssclass:: table-bordered\n",
    ".. rst-class:: midvalign\n",
    "\n",
    "============== ==============================================================\n",
    "Data object    Filename convention (ends with)\n",
    "============== ==============================================================\n",
    "raw            -raw.fif(.gz), -raw_sss.fif(.gz), -raw_tsss.fif(.gz),\n",
    "               _meg.fif(.gz), _eeg.fif(.gz), _ieeg.fif(.gz)\n",
    "events         -eve.fif(.gz)\n",
    "epochs         -epo.fif(.gz)\n",
    "evoked         -ave.fif(.gz)\n",
    "covariance     -cov.fif(.gz)\n",
    "SSP projectors -proj.fif(.gz)\n",
    "trans          -trans.fif(.gz)\n",
    "forward        -fwd.fif(.gz)\n",
    "inverse        -inv.fif(.gz)\n",
    "============== ==============================================================\n",
    "\n",
    "Alternatively, the dash ``-`` in the filename may be replaced with an\n",
    "underscore ``_``.\n",
    "\n",
    "## Basic reports\n",
    "\n",
    "The basic process for creating an HTML report is to instantiate the\n",
    ":class:`~mne.Report` class, then use the :meth:`~mne.Report.parse_folder`\n",
    "method to select particular files to include in the report. Which files are\n",
    "included depends on both the ``pattern`` parameter passed to\n",
    ":meth:`~mne.Report.parse_folder` and also the ``subject`` and\n",
    "``subjects_dir`` parameters provided to the :class:`~mne.Report` constructor.\n",
    "\n",
    ".. sidebar: Viewing the report\n",
    "\n",
    "   On successful creation of the report, the :meth:`~mne.Report.save` method\n",
    "   will open the HTML in a new tab in the browser. To disable this, use the\n",
    "   ``open_browser=False`` parameter of :meth:`~mne.Report.save`.\n",
    "\n",
    "For our first example, we'll generate a barebones report for all the\n",
    ":file:`.fif` files containing raw data in the sample dataset, by passing the\n",
    "pattern ``*raw.fif`` to :meth:`~mne.Report.parse_folder`. We'll omit the\n",
    "``subject`` and ``subjects_dir`` parameters from the :class:`~mne.Report`\n",
    "constructor, but we'll also pass ``render_bem=False`` to the\n",
    ":meth:`~mne.Report.parse_folder` method â€” otherwise we would get a warning\n",
    "about not being able to render MRI and ``trans`` files without knowing the\n",
    "subject.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : jquery.js\n",
      "Embedding : jquery-ui.min.js\n",
      "Embedding : bootstrap.min.js\n",
      "Embedding : jquery-ui.min.css\n",
      "Embedding : bootstrap.min.css\n",
      "Opening raw data file /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/ernoise_raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 19800 ... 85867 =     32.966 ...   142.965 secs\n",
      "Ready.\n",
      "Opening raw data file /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n",
      "Opening raw data file /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Iterating over 3 potential files (this may take some time)\n",
      "Rendering : /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/ernoise_raw.fif\n",
      "Opening raw data file /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/ernoise_raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 19800 ... 85867 =     32.966 ...   142.965 secs\n",
      "Ready.\n",
      "Rendering : /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif\n",
      "Opening raw data file /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n",
      "Rendering : /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_raw.fif\n",
      "Opening raw data file /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Saving report to location /home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_basic.html\n",
      "Rendering : Table of Contents\n",
      "raw\n",
      " ... ernoise_raw.fif\n",
      " ... sample_audvis_filt-0-40_raw.fif\n",
      " ... sample_audvis_raw.fif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_basic.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = mne.datasets.sample.data_path(verbose=False)\n",
    "report = mne.Report(verbose=True)\n",
    "report.parse_folder(path, pattern='*raw.fif', render_bem=False)\n",
    "report.save('report_basic.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report yields a textual summary of the :class:`~mne.io.Raw` files\n",
    "selected by the pattern. For a slightly more useful report, we'll ask for the\n",
    "power spectral density of the :class:`~mne.io.Raw` files, by passing\n",
    "``raw_psd=True`` to the :class:`~mne.Report` constructor. We'll also\n",
    "visualize the SSP projectors stored in the raw data's `~mne.Info` dictionary\n",
    "by setting ``projs=True``. Lastly, let's also refine our pattern to select\n",
    "only the filtered raw recording (omitting the unfiltered data and the\n",
    "empty-room noise recordings):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : jquery.js\n",
      "Embedding : jquery-ui.min.js\n",
      "Embedding : bootstrap.min.js\n",
      "Embedding : jquery-ui.min.css\n",
      "Embedding : bootstrap.min.css\n",
      "Opening raw data file /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n",
      "Iterating over 1 potential files (this may take some time)\n",
      "Rendering : /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif\n",
      "Opening raw data file /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8c1d06ac7b4e45a1e8d9abc54c4d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 13.639 (s)\n",
      "Effective window size : 13.639 (s)\n",
      "Effective window size : 13.639 (s)\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dedc5d397b543a88267d1566467beeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving report to location /home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_raw_psd.html\n",
      "Rendering : Table of Contents\n",
      "raw\n",
      " ... sample_audvis_filt-0-40_raw.fif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_raw_psd.html'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = 'sample_audvis_filt-0-40_raw.fif'\n",
    "report = mne.Report(raw_psd=True, projs=True, verbose=True)\n",
    "report.parse_folder(path, pattern=pattern, render_bem=False)\n",
    "report.save('report_raw_psd.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample dataset also contains SSP projectors stored as *individual files*.\n",
    "To add them to a report, we also have to provide the path to a file\n",
    "containing an `~mne.Info` dictionary, from which the channel locations can be\n",
    "read.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : jquery.js\n",
      "Embedding : jquery-ui.min.js\n",
      "Embedding : bootstrap.min.js\n",
      "Embedding : jquery-ui.min.css\n",
      "Embedding : bootstrap.min.css\n",
      "Iterating over 2 potential files (this may take some time)\n",
      "Rendering : /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_ecg-proj.fif\n",
      "    Read a total of 6 projection items:\n",
      "        ECG-planar-999--0.200-0.400-PCA-01 (1 x 203)  idle\n",
      "        ECG-planar-999--0.200-0.400-PCA-02 (1 x 203)  idle\n",
      "        ECG-axial-999--0.200-0.400-PCA-01 (1 x 102)  idle\n",
      "        ECG-axial-999--0.200-0.400-PCA-02 (1 x 102)  idle\n",
      "        ECG-eeg-999--0.200-0.400-PCA-01 (1 x 59)  idle\n",
      "        ECG-eeg-999--0.200-0.400-PCA-02 (1 x 59)  idle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba0e2aeaf564cb9bd7b07de3fff789b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering : /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis_eog-proj.fif\n",
      "    Read a total of 6 projection items:\n",
      "        EOG-planar-998--0.200-0.200-PCA-01 (1 x 203)  idle\n",
      "        EOG-planar-998--0.200-0.200-PCA-02 (1 x 203)  idle\n",
      "        EOG-axial-998--0.200-0.200-PCA-01 (1 x 102)  idle\n",
      "        EOG-axial-998--0.200-0.200-PCA-02 (1 x 102)  idle\n",
      "        EOG-eeg-998--0.200-0.200-PCA-01 (1 x 59)  idle\n",
      "        EOG-eeg-998--0.200-0.200-PCA-02 (1 x 59)  idle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6f22b2c9f341bd94964d804fe61f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving report to location /home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_proj.html\n",
      "Rendering : Table of Contents\n",
      "ssp\n",
      " ... sample_audvis_ecg-proj.fif\n",
      " ... sample_audvis_eog-proj.fif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_proj.html'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_fname = os.path.join(path, 'MEG', 'sample',\n",
    "                          'sample_audvis_filt-0-40_raw.fif')\n",
    "pattern = 'sample_audvis_*proj.fif'\n",
    "report = mne.Report(info_fname=info_fname, verbose=True)\n",
    "report.parse_folder(path, pattern=pattern, render_bem=False)\n",
    "report.save('report_proj.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we'll pass a specific ``subject`` and ``subjects_dir`` (even though\n",
    "there's only one subject in the sample dataset) and remove our\n",
    "``render_bem=False`` parameter so we can see the MRI slices, with BEM\n",
    "contours overlaid on top if available. Since this is computationally\n",
    "expensive, we'll also pass the ``mri_decim`` parameter for the benefit of our\n",
    "documentation servers, and skip processing the :file:`.fif` files:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : jquery.js\n",
      "Embedding : jquery-ui.min.js\n",
      "Embedding : bootstrap.min.js\n",
      "Embedding : jquery-ui.min.css\n",
      "Embedding : bootstrap.min.css\n",
      "Iterating over 0 potential files (this may take some time)\n",
      "Rendering BEM\n",
      "Using surface: /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/subjects/sample/bem/inner_skull.surf\n",
      "Using surface: /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/subjects/sample/bem/outer_skull.surf\n",
      "Using surface: /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/subjects/sample/bem/outer_skin.surf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7171fa35948944bb8fe06b1f8b0d99d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b7d5df324448bba220c8d81b4b0988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3721d0a56c14826b3f62d1b79505b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving report to location /home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_mri_bem.html\n",
      "Rendering : Table of Contents\n",
      "bem\n",
      " ... bem\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_mri_bem.html'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_dir = os.path.join(path, 'subjects')\n",
    "report = mne.Report(subject='sample', subjects_dir=subjects_dir, verbose=True)\n",
    "report.parse_folder(path, pattern='', mri_decim=25)\n",
    "report.save('report_mri_bem.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at how :class:`~mne.Report` handles :class:`~mne.Evoked` data\n",
    "(we will skip the MRIs to save computation time). The following code will\n",
    "produce butterfly plots, topomaps, and comparisons of the global field\n",
    "power (GFP) for different experimental conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : jquery.js\n",
      "Embedding : jquery-ui.min.js\n",
      "Embedding : bootstrap.min.js\n",
      "Embedding : jquery-ui.min.css\n",
      "Embedding : bootstrap.min.css\n",
      "Iterating over 1 potential files (this may take some time)\n",
      "Rendering : /home/share/neuroinformatics/mne-python/data/tutorials/MNE-sample-data/MEG/sample/sample_audvis-no-filter-ave.fif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b327055bba94be5a4b58126e8ae1559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6baac7d062a4e41864f86ef6208f7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48a1c852d5a4f03bfacc74262a554c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f16e4c62a2744e3b0f2bbf98211488e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcd3336cad24ceeaa0bffa30571dbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee701484d55e419099e102c8a19079de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007a0c86348649d197fa01e8f13a438f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10449c8dc48a47969d2c7485aea0611a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24267c1d8c9946359934276e70d1fe36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd5103b8f9d48a89c8e970d70a2040b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d9cfd1a5e24a2da5f78786036fb036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5b1d67384e43dea3b32cd3ecc454fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0b24408d18493cba7545446af022d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735d36fcff76407a891f299498564e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n",
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5004e7d672bb45c2a9939d45e1955795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | Average EEG reference, active : True, n_channels : 60>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8114364df52c48f889ca3ae3e7943614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple channel types selected, returning one figure per type.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a818b3ec05c4b34ace97cb75727218c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9587853a4e4d95ae1048effc1fe634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a32fa32cd1949c5abf7fdd47c865bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "Saving report to location /home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_evoked.html\n",
      "Rendering : Table of Contents\n",
      "evoked\n",
      " ... sample_audvis-no-filter-ave.fif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/share/neuroinformatics/mne-python/code/notebooks/tutorials/intro/report_evoked.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = 'sample_audvis-no-filter-ave.fif'\n",
    "report = mne.Report(verbose=True)\n",
    "report.parse_folder(path, pattern=pattern, render_bem=False)\n",
    "report.save('report_evoked.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have probably noticed that the EEG recordings look particularly odd. This\n",
    "is because by default, `~mne.Report` does not apply baseline correction\n",
    "before rendering evoked data. So if the dataset you wish to add to the report\n",
    "has not been baseline-corrected already, you can request baseline correction\n",
    "here. The MNE sample dataset we're using in this example has **not** been\n",
    "baseline-corrected; so let's do this now for the report!\n",
    "\n",
    "To request baseline correction, pass a ``baseline`` argument to\n",
    "`~mne.Report`, which should be a tuple with the starting and ending time of\n",
    "the baseline period. For more details, see the documentation on\n",
    "`~mne.Evoked.apply_baseline`. Here, we will apply baseline correction for a\n",
    "baseline period from the beginning of the time interval to time point zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "baseline = (None, 0)\n",
    "pattern = 'sample_audvis-no-filter-ave.fif'\n",
    "report = mne.Report(baseline=baseline, verbose=True)\n",
    "report.parse_folder(path, pattern=pattern, render_bem=False)\n",
    "report.save('report_evoked_baseline.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To render whitened :class:`~mne.Evoked` files with baseline correction, pass\n",
    "the ``baseline`` argument we just used, and add the noise covariance file.\n",
    "This will display ERP/ERF plots for both the original and whitened\n",
    ":class:`~mne.Evoked` objects, but scalp topomaps only for the original.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cov_fname = os.path.join(path, 'MEG', 'sample', 'sample_audvis-cov.fif')\n",
    "baseline = (None, 0)\n",
    "report = mne.Report(cov_fname=cov_fname, baseline=baseline, verbose=True)\n",
    "report.parse_folder(path, pattern=pattern, render_bem=False)\n",
    "report.save('report_evoked_whitened.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to actually *view* the noise covariance in the report, make sure\n",
    "it is captured by the pattern passed to :meth:`~mne.Report.parse_folder`, and\n",
    "also include a source for an :class:`~mne.Info` object (any of the\n",
    ":class:`~mne.io.Raw`, :class:`~mne.Epochs` or :class:`~mne.Evoked`\n",
    ":file:`.fif` files that contain subject data also contain the measurement\n",
    "information and should work):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pattern = 'sample_audvis-cov.fif'\n",
    "info_fname = os.path.join(path, 'MEG', 'sample', 'sample_audvis-ave.fif')\n",
    "report = mne.Report(info_fname=info_fname, verbose=True)\n",
    "report.parse_folder(path, pattern=pattern, render_bem=False)\n",
    "report.save('report_cov.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding custom plots to a report\n",
    "\n",
    "The Python interface has greater flexibility compared to the `command\n",
    "line interface <mne report>`. For example, custom plots can be added via\n",
    "the :meth:`~mne.Report.add_figs_to_section` method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "report = mne.Report(verbose=True)\n",
    "\n",
    "fname_raw = os.path.join(path, 'MEG', 'sample', 'sample_audvis_raw.fif')\n",
    "raw = mne.io.read_raw_fif(fname_raw, verbose=False).crop(tmax=60)\n",
    "events = mne.find_events(raw, stim_channel='STI 014')\n",
    "event_id = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3,\n",
    "            'visual/right': 4, 'face': 5, 'buttonpress': 32}\n",
    "\n",
    "# create some epochs and ensure we drop a few, so we can then plot the drop log\n",
    "reject = dict(eeg=150e-6)\n",
    "epochs = mne.Epochs(raw=raw, events=events, event_id=event_id,\n",
    "                    tmin=-0.2, tmax=0.7, reject=reject, preload=True)\n",
    "fig_drop_log = epochs.plot_drop_log(subject='sample', show=False)\n",
    "\n",
    "# now also plot an evoked response\n",
    "evoked_aud_left = epochs['auditory/left'].average()\n",
    "fig_evoked = evoked_aud_left.plot(spatial_colors=True, show=False)\n",
    "\n",
    "# add the custom plots to the report:\n",
    "report.add_figs_to_section([fig_drop_log, fig_evoked],\n",
    "                           captions=['Dropped Epochs',\n",
    "                                     'Evoked: Left Auditory'],\n",
    "                           section='drop-and-evoked')\n",
    "report.save('report_custom.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a slider\n",
    "\n",
    "Sliders provide an intuitive way for users to interactively browse a\n",
    "predefined set of images. You can add sliders via\n",
    ":meth:`~mne.Report.add_slider_to_section`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "report = mne.Report(verbose=True)\n",
    "\n",
    "figs = list()\n",
    "times = evoked_aud_left.times[::30]\n",
    "for t in times:\n",
    "    figs.append(evoked_aud_left.plot_topomap(t, vmin=-300, vmax=300, res=100,\n",
    "                show=False))\n",
    "    plt.close(figs[-1])\n",
    "report.add_slider_to_section(figs, times, 'Evoked Response',\n",
    "                             image_format='png')  # can also use 'svg'\n",
    "\n",
    "report.save('report_slider.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding coregistration plot to a report\n",
    "\n",
    "Now we see how :class:`~mne.Report` can plot coregistration results. This is\n",
    "very useful to check the quality of the :term:`trans` coregistration file\n",
    "that allows to align anatomy and MEG sensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "report = mne.Report(info_fname=info_fname, subject='sample',\n",
    "                    subjects_dir=subjects_dir, verbose=True)\n",
    "pattern = \"sample_audvis_raw-trans.fif\"\n",
    "report.parse_folder(path, pattern=pattern, render_bem=False)\n",
    "report.save('report_coreg.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ``SourceEstimate`` (STC) plot to a report\n",
    "\n",
    "Now we see how :class:`~mne.Report` handles :class:`~mne.SourceEstimate`\n",
    "data. The following will produce a :term:`stc` plot with vertex\n",
    "time courses. In this scenario, we also demonstrate how to use the\n",
    ":meth:`mne.viz.Brain.screenshot` method to save the figs in a slider.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "report = mne.Report(verbose=True)\n",
    "fname_stc = os.path.join(path, 'MEG', 'sample', 'sample_audvis-meg')\n",
    "stc = mne.read_source_estimate(fname_stc, subject='sample')\n",
    "figs = list()\n",
    "kwargs = dict(subjects_dir=subjects_dir, initial_time=0.13,\n",
    "              clim=dict(kind='value', lims=[3, 6, 9]))\n",
    "for hemi in ('lh', 'rh'):\n",
    "    brain = stc.plot(hemi=hemi, **kwargs)\n",
    "    brain.toggle_interface(False)\n",
    "    figs.append(brain.screenshot(time_viewer=True))\n",
    "    brain.close()\n",
    "\n",
    "# add the stc plot to the report:\n",
    "report.add_slider_to_section(figs)\n",
    "\n",
    "report.save('report_stc.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing report sections\n",
    "\n",
    "The MNE report command internally manages the sections so that plots\n",
    "belonging to the same section are rendered consecutively. Within a section,\n",
    "the plots are ordered in the same order that they were added using the\n",
    ":meth:`~mne.Report.add_figs_to_section` command. Each section is identified\n",
    "by a toggle button in the top navigation bar of the report which can be used\n",
    "to show or hide the contents of the section. To toggle the show/hide state of\n",
    "all sections in the HTML report, press :kbd:`t`, or press the toggle-all\n",
    "button in the upper right.\n",
    "\n",
    ".. sidebar:: Structure\n",
    "\n",
    "   Although we've been generating separate reports in each of these examples,\n",
    "   you could easily create a single report for all :file:`.fif` files (raw,\n",
    "   evoked, covariance, etc) by passing ``pattern='*.fif'``.\n",
    "\n",
    "\n",
    "## Editing a saved report\n",
    "\n",
    "Saving to HTML is a write-only operation, meaning that we cannot read an\n",
    "``.html`` file back as a :class:`~mne.Report` object. In order to be able\n",
    "to edit a report once it's no longer in-memory in an active Python session,\n",
    "save it as an HDF5 file instead of HTML:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "report.save('report.h5', overwrite=True)\n",
    "report_from_disk = mne.open_report('report.h5')\n",
    "print(report_from_disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows the possibility of multiple scripts adding figures to the same\n",
    "report. To make this even easier, :class:`mne.Report` can be used as a\n",
    "context manager:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with mne.open_report('report.h5') as report:\n",
    "    report.add_figs_to_section(fig_evoked,\n",
    "                               captions='Left Auditory',\n",
    "                               section='evoked',\n",
    "                               replace=True)\n",
    "    report.save('report_final.html', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the context manager, the updated report is also automatically saved\n",
    "back to :file:`report.h5` upon leaving the block.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
